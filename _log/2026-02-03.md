---
layout: log
title: Big graphs, small graphs
date: 2026-02-03
math: True
tags: [graph-neural-networks, reinforcement-learning]
---

## Summary
* Read *Inductive Representation Learning on Large Graphs* by Hamilton et al.  
* More work on Sutton and Barto.

## Notes
1. This is the paper that introduced `GraphSAGE`. 
2. An important term I learned here is *transductive*, which refers to reasoning or learning that moves from specific examples to specific, related examples rather than generalizing to broad rules. The opposite is "inductive", which is the inference of general laws from specific examples. 
4. The goal of the paper is to handle the fact that graph neural networks are inherently transductive: that they don't generalise well to unseen nodes. They do this via the introduction of the `GraphSAGE` message passing framework.
5. The application here is mostly for systems where you need to generate embeddings for *non-fixed* graph representations. If my graph *evolves*, the standard fixed representation falls completely asunder. 
6. Ah, hold on - transductive methods are those that need to see the *whole* graph during training. I see! An inductive method, then, is one that will allow you to generate embeddings for unseen nodes or graphs *without* training.
7. `GraphSAGE` stands for "graph sample and aggregate". Something cool here is that the aggregation functions are actually differentiable: they're *trained* in `GraphSAGE` to aggregate in the most appropriate way. Very clever...
8. From the framework described in Gilmer et al, the message passing network here is a set of aggregator functions, which are modulated by a set of weight matrices that propagate information over different layers of the model. 
9. The update step here is when the current node representation and the aggregation are concatenated and sent through a fully connected layer + activation function. The readout is, for the sake of the network, a replacement of the previous graph.
10. The subtlety here is in the way the aggregator function can be defined. There are three kinds of aggregator discussed in the paper:
    * The standard mean aggregator 
    * An LSTM aggregator
    * A pooling aggregator... the motivation for which eludes me. I need to think about this when I write up my literature review...
11. As expected, the results are stellar...

## Sutton and Barto
1. A key piece of terminology - *sample updates*. These are a class of methods that involve looking forward to a successor state, using the value of the successor and the reward obtained from accessing that state and then updating the current state using that successor reward/value.
2. Another quantity: TD error, which is defined as $$ \delta_t = R_{t+1} + \gamma V(S_{t+1}) - V(S_t)$$. This will show up quite a few times throughout this book: it's a rough difference between the estimated value of the current state and the better estimate provided by the TD method. 

## Remarks
* It's worth mentioning that graph neural networks are *incredibly* powerful. They're actually a fundamental feature of the `AlphaFold` system that won Hassabis and Jumper a Nobel. 
* Going too slowly through Sutton and Barto. I've been tired when coming back from work these last few days... 
