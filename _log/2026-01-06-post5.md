---
layout: log
title: Number and interaction
date: 2026-01-06
tags: [deep-learning, graph-neural-networks, reinforcement-learning]
---

## Summary
* Finished reading through Sanchez-Gonzales et. al. (2018). 
* Almost finished Chapter 2 of Sutton and Barto. Slow progress today, but very interesting reading. 

## Notes
* The generalisation of the forward planning graph was really interesting - it seems to me that the failure to generalise for larger links in the swimmer could be a result of different modes of interaction that emerge only with larger systems. More on this in this week's literature review.
* I like reading DeepMind papers - they're always so excellently written. I have to pay very close attention because they're crammed with important details, which is why I'm okay with spending a bit of time on these. 
* From Sutton and Barto: it's very interesting how optimism translates into a tendency exploration in a stationary problem. The interpretation provided (optimists switch actions because they'll get disappointed at the rewards they're recieving at first) is also an interesting perspective and totally divorced from my typically mechanistic way of seeing the world. 

# Remarks
* I should probably start reading more psychology. This may take a while to action given that I'm unironically about 10% of the way through War and Peace right now. 
* That being said, it's awesome how many parallels there are between statistical physics and reinforcement learning. It goes without saying almost, given that the essence of a statistical-physical process is typically some form of diffusion, which in itself is a very efficient mechanism for search. I'd write about this, but I'm trying to avoid being *too* half-baked and philosophical. :) 