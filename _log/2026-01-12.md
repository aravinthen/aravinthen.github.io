---
layout: log
title: The road to transformers
date: 2026-01-12
tags: [reinforcement-learning, deep-learning]
---

## Summary
* Read *Deep Reinforcement Learning that matters* by Henderson et al. 
* Started reading *Sequence-to-sequence learning with Neural Networks* by Sutskever, Vinyals and Le. 
* More progress on Sutton and Barto, although much less than I'd hoped. 

## Notes
1. So basically, DRL is just damned hard and changing anything messes everything up. Got it. 
2. Jokes aside, the paper was really interesting. Raises quite a few of the pitfalls of DRL implementations and even bootstrapping and power analysis as a means of assessing whether significant differences exist within RL runs. 
3. The effect of the architecture having a large impact on results was also quite an interesting point that was clearly illustrated. I'm still in a phase of thinking where NNs are just black boxes that just fit data... but that's the issue, isn't it? We're not fitting to data, we're fitting to discounted values. DRL is different beast *entirely*.
4. I want to thoroughly understand transformers, so I'm starting with the foundational papers that build up to it. The first of these is *Sequence-to-Sequence learning with Neural Networks*. The first thing I'm noticing is that the paper is an absolutely pleasure to read. :)

## Remarks
* It's always motivating to go back and look at the results of even simple deep networks. What an absolutely magnificent field of engineering.   