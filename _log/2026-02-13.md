---
layout: log
title: Scorched by the Torch(RL)
date: 2026-02-13
math: True
tags: [reinforcement-learning]
---

## Summary
* Finished reading *Torch-RL: A Data Driven Decision-Making Library for PyTorch* - Bou et al. 
* Starting planning my RL projects over the next week.

## Notes
* So, `TensorDict` can enable the development of RL systems that don't actually require any interfacing with the policy or even the algorithm. This is *pure* modularity, even more decoupled than the approach I saw in `RLLib`.
* In essence, a `TensorDict` is a dictionary that also takes shapes as well as keys. You can also index keys and shapes in an interchangeable way.
* Ah, here we go: you can actually use `TorchRL` to handle distribution. This effectively makes it capable of handling the same kinds of tasks as `Ray`... so why use `Ray` at all? It looks like the *emphasis* on `Ray RLlib` is massive distribution. Essentially - `TorchRL` for mid-level control, `Ray` if you have hundreds of computers to command.
* There are unifying constructs available in `TorchRL` to handle a variety of environment objects. I think the other libraries that I've found are roughly similar in capability here.
* An emphasis here is `PyTorch` interoperability. As a result, you'll have to *really* know your `PyTorch`. 
* "Data collectors iteratively compute the actions to be executed, pass those to the environments (real or simulated), and can handle resetting when and where required." - I've always thought that this was the logical way to conduct this kind of experiment!
* It's clear that using `TorchRL` really isn't easy. However, it's also somewhat clear that it is *exceptionally* powerful and very suitable for research engineering. The customizability available for the networks underlying the RL agent is impressive: I could use essentially any deep learning architecture implemented in `PyTorch` and somehow get it to work on `TorchRL`. I do think it's quite interesting that of all things to specify, the *loss* functions are given detail. I daresay this is an indication that `TorchRL` is very much centred on *deep* reinforcement learning.
* The paper states directly that `TorchRL` allows for the replication of distributed techniques like `IMPALA`, a framework created by OpenAI. The results listed in this paper are absolutely **amazing**.

### Project
* I have decided to build some RL systems. I've got an understanding of the theoretical ideas underpinning RL, but at this rate it'll be months before I have a working system. This is something that I would like to change.
* There are multiple levels towards RL development - this can quite clearly be seen in how the libraries that I've been reading about over the last week have been developed. I think that for the algorithms that I'll be implementing over the next weeks, there ouhg