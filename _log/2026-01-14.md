---
layout: log
title: Less messy sequences
date: 2026-01-14
tags: [deep-learning]
---

## Summary
* Read [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy.

## Notes
* This is one of the resources from Ilya Sutskever's list - I'm hoping to grind my way through it gradually. This is not to forget that my main goal here is deep reinforcement learning, but I want to get the foundations of DRL down before I start diving into that body of literature.
* I liked the analogy here, where RNNs are likened to programs. Regardless, I want to keep it simple: an RNN is a function that is influenced by the inputs it's received in the past. 
* The core of the mechanism that allows this is quite simple:
    1. You have a set of weights that handle the input,
    2. You have a set of weights that handle the previous hidden state.
    3. The hidden state is updated with respect to the sum of the input and the previous hidden state (with the addition of tangent nonlinearity).
    4. A final set of hidden weights process the output.
* "RNNs are neural networks and everything works monotonically better (if done right) if you put on your deep learning hat and start stacking models up like pancakes." Nice. :)
* LSTMs are mentioned in the post as having "a more powerful update function and appealing backpropagation dynamics". Very interestingly, the work uses LSTMs for all experiments and Andrej himself uses the terms interchangeably.
* *The essence of a recurrent neural network is to take a character as input and predict the probability of the next character based on its training.* This is incredibly generalizable. 
* There's a subtlety to the training of these networks. In vanilla network training the goal is to predict disparate labels - there's no meaning to the order with which samples are put through it for training. With RNNs, the goal is keep training until the prediction for the next character is consistently correct. This, I suppose, is the reason that it's so hard to parallelise them so effectively. 
* Interesting note at the end of the article, where Andrej refers to the explicit use of reinforcement learning to handle non-differentiable learning tasks.


## Remarks
1. Make no mistake - these are just very, very deep feedforward neural networks. In fact, they're even simpler given that the weights for each layer are exactly the same! 
2. It's really important to realise that whilst seeing an older technology when you're reading about it for the first time makes it seem wonderful, there *are* drawbacks that aren't present in the exposition.
3. The main drawback of a vanilla RNN is they struggle with long sequences due to vanishing/exploding gradients, slow training due to lack of parallelization and overfitting.
4. Reading LSTM generated Tolstoy was somewhat eerie given my current reading. :)  
