---
title: Deep Architecture Implementations
category: projects
---

## Architectures
1. [Transformer](https://github.com/aravinthen/deep-architectures/tree/main/transformers)

## Motivation
Having committed to mastering deep learning, I quickly realised that randomly following courses and proscribed pathways didn't really work for me. You can solve a course exercise a million times and still not *truly* get it - what really makes content stick is **pain**.
Reimplementing papers is a painful process: I know this from experience. I spent six months trying to reimplement a paper during graduate school, only to realise that the method described in the paper didn't work for the problem I wanted it to solve.

I spent the next two weeks scrambling to develop a working technique from the ashes of the software that I reimplemented. This process taught me more about software development, statistical physics and Monte Carlo methods than everything I'd done in the two years of research that had led up to that point. 

It's time to actively engage with deep learning as an engineering task. To achieve this, I've decided to reimplement deep architectures from literature and spend time in mastering their effective use. The essence of this activity isn't just to get practice using PyTorch: I want to get my architectures *running* and solving the problems that they were designed for. 

When I started this project, I was hoping to just build an architecture every week and work through papers by just implementing them. I realise that this is a suboptimal way of really learning how an architecture works: deep care and attention must be taken in building and *using* the architectures at hand. That is what I want this project to be.

The main repository for this project can be found [here](https://github.com/aravinthen/deep-architectures/). 

