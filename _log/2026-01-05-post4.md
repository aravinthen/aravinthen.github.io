---
layout: log
title: Bandits and graph neural networks
date: 2026-01-05
tags: [deep-learning, graph-neural-networks, reinforcement-learning]
---

## Summary
* Started reading Graph networks as learnable physics engines for inference and control - Sanchez-Gonzales et. al. (2018). Didn't manage to finish it given that I started my lunch break later than usual, but this was a useful reading session. 

## Remarks
1. GNNs are powerful: they generalise nicely and actually have a pretty intuitive explanation. They're nothing more than a means of imposing inductive bias into the learning process. The graph networks that I was studying today could be used for forward prediction (they can act as a time evolution operator), inference (they can identify and predict hidden properties of the graph) and control (a mix of both).
2. A few years ago when I was messing around with data science, I was repeatedly told about the importance of feature engineering. GNNs seem to be an automated, differentiable means of carrying this out.
3. Progress on Sutton and Barto. Solved some exercises from Chapter 2, although this stuff is simple business. As part of this task, I wrote my own bandit and spent a bit too much time playing about with it. :)